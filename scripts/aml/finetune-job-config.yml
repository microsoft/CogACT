$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
#name: # if given, needs to be changed every time (by e.g. appending timestamp)
display_name: CogACT Fine-tuning on Stanford KUKA Dataset
description: Fine-tune CogACT-Base model
code: ../..  # Points to the root of the repository

environment: azureml:<aml env_name>:<env version>
compute: azureml:<your_compute_name>

# Note: in the command below, the arguments --pretrained_checkpoint are missing w.r.t. the example command in the main README.
# The reason is that they will be handled by the wrapper script train_aml.py directly, since they are resolved at runtime from AzureML mount points.
command: >-
  python scripts/aml/train_aml.py
  --vla.type prism-dinosiglip-224px+oxe+diffusion
  --vla.data_mix stanford_kuka_multimodal_dataset_converted_externally_to_rlds
  --vla.expected_world_size 4
  --vla.global_batch_size 64
  --vla.per_device_batch_size 16
  --vla.learning_rate 2e-5
  --run_id cogact_stanford_kuka_finetune
  --image_aug True
  --save_interval 1000
  --repeated_diffusion_steps 8
  --future_action_window_size 15
  --action_model_type DiT-B
  --is_resume False
  --wandb_project <wandb_project_name>
  --wandb_entity <wandb_entity_name>
  --hf_token HF_TOKEN
  --data_root_dir ${{inputs.data_root_dir}}
  --run_root_dir ${{outputs.run_root_dir}}

# Environment variables
environment_variables:
  HF_TOKEN: ${HF_TOKEN}
  WANDB_API_KEY: ${WANDB_API_KEY}
  HF_HOME: ${{outputs.hf_home}}
  PYTHONUNBUFFERED: "1"
  GPU_COUNT: "4"  # Set explicit GPU count per node for distributed training
  NCCL_DEBUG: "INFO"
  NCCL_SOCKET_IFNAME: "^lo,docker0"  # Avoid using loopback interface
  NCCL_IB_DISABLE: "1"  # Disable InfiniBand if causing issues
  MASTER_ADDR: "localhost"
  MASTER_PORT: "29500"
  CUDA_DEVICE_ORDER: "PCI_BUS_ID"  # Ensure PyTorch can find all GPUs

# Inputs
inputs:
  # Dataset on which the base model will be fine-tuned
  data_root_dir:
    type: uri_folder
    path: azureml://datastores/<datastore_name>/paths/<dataset_folder_name>
    mode: ro_mount  # read-only mount for finetuning dataset

# Storage configuration for outputs, e.g. finetuned model checkpoints
outputs:
  # Checkpoints and metadata from the finetuning job
  run_root_dir:
    type: uri_folder
    path: azureml://datastores/<datastore_name>/paths/<outputs_folder_name>
    mode: rw_mount  # read-write mount for training outputs
  #Â Directory where HuggingFace cached models are stored
  hf_home:
    type: uri_folder
    path: azureml://datastores/<datastore_name>/paths/<hf_cache_folder_name>
    mode: rw_mount  # read-write mount for HuggingFace cache

# Compute resources
resources:
  instance_count: 1  # Number of nodes
  shm_size: 32g      # Larger shared memory size for better distributed training performance

# Experiment tracking
experiment_name: cogact-finetune
tags:
  model: "CogACT-Base" # Or CogACT-Small, etc.
  dataset: "<dataset_name>"
  training_type: "fine-tuning"
